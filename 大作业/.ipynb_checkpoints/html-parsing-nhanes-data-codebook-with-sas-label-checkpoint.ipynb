{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML Parsing NHANES Data Codebook with SAS label\n",
    "### Li-Chia Chen\n",
    "### 27Feb2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "While I am doing a project using the NHANES dataset, I find that it was hard to locate the desired variable and difficult to tell the meaning of each variable after feature selection. Therefore, I decided to parse the information from the NHANES website using **Beautiful Soup**. \n",
    "\n",
    "There is already one codebook with detailed description here: https://www.kaggle.com/cdc/national-health-and-nutrition-examination-survey/discussion/47796\n",
    "\n",
    "\n",
    "In this notebook the main purpose is to extract the sas labels from the data documentations websites in the 5 main categories:\n",
    "- Demographics: https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Demographics&CycleBeginYear=2013\n",
    "- Dietary: https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Dietary&CycleBeginYear=2013\n",
    "- Examination: https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Examination&CycleBeginYear=2013\n",
    "- Laboratory: https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Laboratory&CycleBeginYear=2013\n",
    "- Questionnaire: https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Questionnaire&CycleBeginYear=2013\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_main(URL, links, category):\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    table = soup.find('table')\n",
    "\n",
    "    for link in table.find_all('a'):\n",
    "        if str(link.get('href')).endswith('.htm') == True:\n",
    "            link_j = urllib.parse.urljoin('https://wwwn.cdc.gov/', link.get('href'))\n",
    "            links[category].append(link_j)\n",
    "\n",
    "\n",
    "urls = {'DM':'https://wwwn.cdc.gov/nchs/nhanes/search/datapage.aspx?Component=Demographics&CycleBeginYear=2013',\n",
    "        'DIET':'https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Dietary&CycleBeginYear=2013',\n",
    "        'EXAM':'https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Examination&CycleBeginYear=2013',\n",
    "        'LAB':'https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Laboratory&CycleBeginYear=2013',\n",
    "        'QUES':'https://wwwn.cdc.gov/nchs/nhanes/Search/DataPage.aspx?Component=Questionnaire&CycleBeginYear=2013'}\n",
    "\n",
    "links = {v:[] for v in urls.keys()}\n",
    "\n",
    "for c, URL in urls.items():\n",
    "    print(c, URL)\n",
    "    parse_main(URL, links, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_nhanes(links, codes):\n",
    "    for c, URLs in links.items():\n",
    "        for URL in URLs:\n",
    "            # access webs site\n",
    "            page = requests.get(URL)\n",
    "\n",
    "            # parse data\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            containers = soup.find_all('dl')\n",
    "            for i in containers:\n",
    "                try:\n",
    "                    varname = str(i.find(\"dt\",string=\"Variable Name: \").findNext(\"dd\").text)\n",
    "                    saslabel = str(i.find(\"dt\",string=\"SAS Label: \").findNext(\"dd\").text)\n",
    "#                     print(varname, saslabel)\n",
    "                    codes['category'].append(c)\n",
    "                    codes['variable'].append(varname.strip())\n",
    "                    codes['label'].append(saslabel.strip())\n",
    "                except:\n",
    "#                     print(f'error in {URL} {i}')\n",
    "                    pass\n",
    "    return codes\n",
    "\n",
    "codes = {\"category\": [], \"variable\": [], \"label\": []}\n",
    "\n",
    "\n",
    "parse_nhanes(links, codes)\n",
    "\n",
    "\n",
    "codebook = pd.DataFrame(codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the value_counts() above, you can see that there are several repeated varaibles due to the data design for the NHANES dataset. To easily match each variable I have list the unique variables separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_unique = codebook[['variable', 'label']].drop_duplicates(subset=['variable'])\n",
    "print(code_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_unique.to_csv('nhanes_2013_2014_codebook.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
